<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="./index.css" />
    <title>First Contact</title>
  </head>
  <body>
    <img src="./cover.png" />
    <blockquote>
      <h1 id="first-contact">First Contact</h1>
      <p>
        An interactive installation questioning our interpretation of exotic
        consciousness
      </p>
      <p>Mixed media, AI, generative art</p>
      <p>By Nino Filiu</p>
    </blockquote>
    <p>
      First contact with alien civilizations, conversation with artificial
      intelligences, abstract art contemplation: these are all forms of esoteric
      communication with an entity supposedly conscious that interacts with
      intent. But what if the impression of consciousness and intent doesn&#39;t
      emerge from the entity we&#39;re communicating with, but rather from
      within ourselves?
    </p>
    <p>
      On August 6, 1967, astrophysicist Jocelyn Bell Burnell picked up a radio
      signal that science couldn&#39;t yet explain. The code name for the signal
      was LGM-1, standing for &quot;little green men 1&quot;, because even for
      some top scientists, only intelligent extraterrestrial life could explain
      the phenomenon. It seems as if we can&#39;t help but believe that there
      always must be something conscious behind unexplained signals, whether
      they come from a distant star, a machine, or the depths of the ocean. That
      is based on this observation that First Contact makes sense.
    </p>
    <p>
      First Contact is an installation where a stream of abstract visuals
      appears on a screen in front of the spectator, whose face expression and
      hand positions are being detected and fed into a program that makes the
      video evolve in real time; for example, when the spectator is first
      perceived, the visuals &quot;awaken&quot;, but most interactions are less
      direct and based on whole entire sequences of movements, thereby creating
      some kind of exotic conversation between the spectator and the machine.
    </p>
    <p>
      First Contact does not take the path of imitative AIs like ChatGPT or
      Blade Runner&#39;s Android, but rather something that could be called
      delphic AI. The goal is not to decipher and talk the language, but rather
      to feel the complexity of the language itself and derive from it an
      illusion of sentience.
    </p>

    <h2 id="software-components">Software components</h2>
    <p>
      The program is a web application that runs on Chromium on the Raspberry.
      It does face expression and hand detection from camera input thanks to AI
      models provided by Google&#39;s Tensorflow, then a piece of software,
      thereafter refered to as The Algorithm, has been written specially for the
      artwork that generates abstract visuals based on these perceived inputs.
    </p>
    <p>
      All software components are products that allows the use of them in
      artistic endeavors, whether commercial or non-commercial.
    </p>
    <p>
      All software components are free and open source, even The Algorithm.
      License details and source code links:
    </p>
    <ul>
      <li>
        Chromium
        <ul>
          <li>License: BSD 2.0</li>
          <li>
            Source code:
            <a href="https://src.chromium.org/">src.chromium.org</a>
          </li>
        </ul>
      </li>
      <li>
        Tensorflow
        <ul>
          <li>License: Apache 2.0</li>
          <li>
            Source code:
            <a href="https://github.com/tensorflow/tensorflow"
              >github.com/tensorflow/tensorflow</a
            >
          </li>
        </ul>
      </li>
      <li>
        Algorithm
        <ul>
          <li>License: MIT</li>
          <li>
            Source code:
            <a href="https://github.com/ninofiliu/first-contact"
              >github.com/ninofiliu/first-contact</a
            >
          </li>
        </ul>
      </li>
    </ul>
    <h2 id="physical-components">Physical components</h2>
    <ul>
      <li>
        1x Philips UVSH 14HT3152/41
        <ul>
          <li>Screen type: CRT</li>
          <li>Weight: 20kg approx</li>
          <li>Video signal input: SCART</li>
        </ul>
      </li>
      <li>
        1x Raspberry PI 4 model B
        <ul>
          <li>Video signal output: HDMI</li>
          <li>Power supply connector: USB-C</li>
          <li>Power input: 5V DC</li>
        </ul>
      </li>
      <li>1x Raspberry PI Camera module</li>
      <li>1x Raspberry PI power supply module</li>
      <li>1x HDMI to SCART converter</li>
    </ul>
    <h2 id="dimensions">Dimensions</h2>
    <p>55cm x 65cm x 70cm approx</p>
    <p>
      Installation render - the monitor is not the same model, but it basically
      looks like this:
    </p>
    <img src="./dimensions.png" />
  </body>
</html>
